# RPC Transaction Crawler Example

The RPC crawler provides a way to analyze the Solana blockchain by processing transactions in batches. It revolves around tracking an account (usually a program address) that is included in the transactions of interest.

## Example Overview

This is a basic example of implementing a Carbon indexer using an RPC crawler. It demonstrates a full flow of how a simple indexer might be built. The goal is to analyze the Jupiter Swap program and apply custom logic to each transaction that includes a Jupiter Swap Event as the _last instruction_. This is defined by the transaction pipe. Additionally, we will apply custom logic for each instruction within the Jupiter Swap program, regardless of whether the transaction matches the schema. This is handled by the instruction pipe.

```rust
let test_account = Pubkey::from_str("JUP6LkbZbjS1jKKwapdHNy74zcZ3tLUZoi5QNyVTaV4").unwrap();

let filters = Filters::new(
    None, // No specific account filtering
    None, // No before signature
    None, // No until signature
);
```

In this example, we prepare the account and filters for the crawler. Since this is a basic setup, we are not using any filters, but you can easily add them using the `solana_sdk` types. For instance, more complex filters might look like this:

```rust
let complex_filters = Filters::new(
    Some(vec![account1, account2]),
    Some(Signature::from_str("(tx_signature)").unwrap()),
    None,
);
```

## Building the RPC Transaction Crawler

To build the RPC Transaction Crawler, we use the `RpcTransactionCrawler` struct from the Carbon core crate, which implements the `Datasource` trait, making it a suitable data source for Carbon pipelines.

```rust
let transaction_crawler = RpcTransactionCrawler::new(
    "https://api.mainnet-beta.solana.com".to_string(), // RPC URL
    test_account,                                      // Test account
    1,                                                 // Batch limit
    Duration::from_secs(5),                            // Polling interval
    filters,                                           // Filters
    Some(CommitmentConfig::finalized()),               // Commitment config
    20,                                                // Max concurrent requests
);
```

Now that we have the crawler, we can use it as the data source in our pipeline:

```rust
carbon_core::pipeline::Pipeline::builder()
    .datasource(transaction_crawler)
    /* ... */
```

## Key Components

### Transaction Pipe

With the Jupiter Swap Program Decoder crate available (generated by the Carbon CLI and published to `crates.io`), we can use it to simplify building our indexer.

First, define the programs youâ€™re interested in. In this example, it's the Jupiter Swap program:

```rust
instruction_decoder_collection!(
    AllInstructions, AllInstructionTypes, AllPrograms,
    JupSwap => JupiterDecoder => JupiterInstruction
);
```

Now that we have the necessary enums and types, we can create the schema and apply it to the transaction pipe. Our schema requires a Jupiter Swap Event to be the last instruction in a transaction:

```rust
static JUPITER_SCHEMA: Lazy<TransactionSchema<AllInstructions>> = Lazy::new(|| {
    schema![
        any
        [
            AllInstructionTypes::JupSwap(JupiterInstructionType::SwapEvent),
            "jup_swap_event",
            []
        ]
    ]
});
```

Next, we create the transaction processor that defines custom business logic when a transaction matches the schema:

```rust
#[derive(Clone, Debug, Deserialize)]
pub struct JupOutput {
    jup_swap_event: DecodedInstruction<JupiterInstruction>,
}

pub struct JupTransactionProcessor;

#[async_trait]
impl Processor for JupTransactionProcessor {
    type InputType = JupOutput;

    async fn process(&self, data: Self::InputType) -> CarbonResult<()> {
        println!("Matched Jupiter Swap Event transaction");

        if let JupiterInstruction::SwapEvent(SwapEvent {
            amm,
            input_mint,
            input_amount,
            output_mint,
            output_amount,
        }) = data.jup_swap_event.data
        {
            println!("AMM: {}", amm);
            println!("Input Mint: {}", input_mint);
            println!("Input Amount: {}", input_amount);
            println!("Output Mint: {}", output_mint);
            println!("Output Amount: {}", output_amount);
        }

        Ok(())
    }
}
```

The output structure for the matched transaction should include all the instructions mentioned in the schema, in the order defined. This allows the automatic code generation to handle the parsing correctly. You can then use pattern matching to process the `JupOutput` instructions and apply custom logic.

Add the transaction pipe to the pipeline:

```rust
carbon_core::pipeline::Pipeline::builder()
    .datasource(transaction_crawler)
    .transaction(JUPITER_SCHEMA.clone(), JupTransactionProcessor)
```

### Instruction Pipe

The process for the instruction pipe is similar. We can use the auto-generated JupiterDecoder, and manually create the processor for custom logic:

```rust
pub struct JupInstructionProcessor;

#[async_trait]
impl Processor for JupInstructionProcessor {
    type InputType = (
        InstructionMetadata,
        DecodedInstruction<JupiterInstruction>,
        Vec<NestedInstruction>,
    );

    async fn process(&self, data: Self::InputType) -> CarbonResult<()> {
        println!("Matched Jupiter instruction: {:#?}", data);

        match data.1.data {
            JupiterInstruction::SwapEvent(SwapEvent {
                amm,
                input_mint,
                input_amount,
                output_mint,
                output_amount,
            }) => {
                println!("AMM: {}", amm);
                println!("Input Mint: {}", input_mint);
                println!("Input Amount: {}", input_amount);
                println!("Output Mint: {}", output_mint);
                println!("Output Amount: {}", output_amount);
            }
            JupiterInstruction::FeeEvent(_) => {}
            _ => {}
        };

        Ok(())
    }
}
```

We are free to match against the instruction data and implement custom logic for each instruction type we encounter.

Finally, add the instruction pipe to the pipeline and complete the Carbon indexer setup:

```rust
carbon_core::pipeline::Pipeline::builder()
    .datasource(transaction_crawler)
    .transaction(JUPITER_SCHEMA.clone(), JupTransactionProcessor)
    .instruction(JupiterDecoder, JupInstructionProcessor)
    .build()?
    .run()
    .await?;
```

With this, the RPC transaction crawler is fully integrated into the Carbon pipeline, ready to analyze and process Jupiter Swap transactions on Solana.
